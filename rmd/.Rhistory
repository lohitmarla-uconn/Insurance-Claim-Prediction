idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
#check for equal proportions of number of claims
table(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
table(insurance.data.test$insuranceclaim)/nrow(insurance.data.test)
#full binary logit model
full.logit <- glm(insuranceclaim ~ . ,data = insurance.data.train,
family = binomial(link = "logit"))
summary(full.logit)
car::qqPlot(residuals(full.logit), main = NA, pch = 19, col = 2, cex = 0.7)
shapiro.test(residuals(full.logit))
#null binary logit model
null.logit <- glm(insuranceclaim ~ 1 ,data = insurance.data.train,
family = binomial(link = "logit"))
summary(null.logit)
car::qqPlot(residuals(null.logit), main = NA, pch = 19, col = 2, cex = 0.7)
shapiro.test(residuals(null.logit))
both.logit <- step(full.logit,
direction="both",trace=0, data = insurance.data.train)
formula(both.logit)
summary(both.logit)
car::qqPlot(residuals(both.logit), main = NA, pch = 19, col = 2, cex = 0.7)
shapiro.test(residuals(both.logit))
extpts <- which(abs(residuals(both.logit)) > 3*sd(residuals(both.logit)))
nrow(insurance.data.train)
length(extpts)
data.train.2 <- insurance.data.train[-extpts,]
full.logit <- glm(insuranceclaim ~ . ,data = data.train.2,
family = binomial(link = "logit"))
both.logit.extpts <- step(full.logit,
direction="both",trace=0, data = data.train.2)
formula(both.logit.extpts)
summary(both.logit.extpts)
car::qqPlot(residuals(both.logit.extpts), main = NA, pch = 19, col = 2, cex = 0.7)
shapiro.test(residuals(both.logit.extpts))
#Baysian Information Criteria
BIC(both.logit)
BIC(full.logit)
BIC(null.logit)
pred.both <- predict(both.logit, newdata = insurance.data.test, type="response")
pred.full <- predict(full.logit, newdata = insurance.data.test, type="response")
(table.both <- table(pred.both > 0.5, insurance.data.test$insuranceclaim))
(table.full <- table(pred.full > 0.5, insurance.data.test$insuranceclaim))
(accuracy.both <- round((sum(diag(table.both))/sum(table.both))*100,2))
(accuracy.full <- round((sum(diag(table.full))/sum(table.full))*100,2))
pred.both <- predict(both.logit, newdata = insurance.data.train, type="response")
pred.full <- predict(full.logit, newdata = insurance.data.train, type="response")
(table.both <- table(pred.both > 0.5, insurance.data.train$insuranceclaim))
(table.full <- table(pred.full > 0.5, insurance.data.train$insuranceclaim))
(accuracy.both <- round((sum(diag(table.both))/sum(table.both))*100,2))
(accuracy.full <- round((sum(diag(table.full))/sum(table.full))*100,2))
both.logit.backward <- step(full.logit,
direction="backward",trace=0, data = insurance.data.train)
formula(both.logit.backward)
summary(both.logit.backward)
car::qqPlot(residuals(both.logit.backward), main = NA, pch = 19, col = 2, cex = 0.7)
shapiro.test(residuals(both.logit.backward))
both.logit.forward <- step(full.logit,
direction="forward",trace=0, data = insurance.data.train)
formula(both.logit.forward)
summary(both.logit.forward)
car::qqPlot(residuals(both.logit.forward), main = NA, pch = 19, col = 2, cex = 0.7)
shapiro.test(residuals(both.logit.forward))
pred.both.forward <- predict(both.logit.forward, newdata = insurance.data.test, type="response")
pred.both.backward <- predict(both.logit.backward, newdata = insurance.data.test, type="response")
(table.both.forward <- table(pred.both.forward > 0.5, insurance.data.test$insuranceclaim))
(table.full.backward <- table(pred.both.backward > 0.5, insurance.data.test$insuranceclaim))
(accuracy.both.forward <- round((sum(diag(table.both.forward))/sum(table.both.forward))*100,2))
(accuracy.full.backward <- round((sum(diag(table.full.backward))/sum(table.full.backward))*100,2))
# Binomial Full Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
cv_results$Accuracies <- as.numeric(cv_results$Accuracies)
mean_accuracy <- mean(cv_results$Accuracies, na.rm = TRUE)
mean_accuracy
# Binomial Logit Model - K fold validation
# Binomial Both Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- step(full.logit,
direction="both",trace=0, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
cv_results$Accuracies <- as.numeric(cv_results$Accuracies)
mean_accuracy <- mean(cv_results$Accuracies, na.rm = TRUE)
mean_accuracy
# Binomial Logit Model - K fold validation
# Classification and Regression Trees
library(rpart)
bank.data$y <- as.factor(ifelse(bank.data$y == "yes", 1, 0))
# Classification and Regression Trees
library(rpart)
insurance.data$insuranceclaim <- as.factor(ifelse(insurance.data$insuranceclaim == "yes", 1, 0))
col_class <- sapply(1:ncol(insurance.data), function(x) class(insurance.data[, x]))
col_id <- which(col_class == "character")
for(i in 1:length(col_id)){
insurance.data[,col_id[i]] <- as.factor(insurance.data[, col_id[i]])
}
col_class
col_id
set.seed(123457)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
summary(insurance.data.train$insuranceclaim)/nrow(insurance.data.test)
idx
set.seed(123457)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
summary(insurance.data.train$insuranceclaim)/nrow(insurance.data.test)
set.seed(123457)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
summary(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
set.seed(123457)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
summary(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
insurance.data.train
which(insurance.data.train$insuranceclaim == 1)
str(insuranceclaim)
str(insurance.data.train)
strats
# Classification and Regression Trees
library(rpart)
insurance.data.dup <- read.csv("~/Documents/GitHub/GitHub/Insurance-Claim-Prediction/data/insurance.csv")
insurance.data <- insurance.data.dup
insurance.data$insuranceclaim <- as.factor(ifelse(insurance.data$insuranceclaim == "yes", 1, 0))
col_class <- sapply(1:ncol(insurance.data), function(x) class(insurance.data[, x]))
col_id <- which(col_class == "character")
for(i in 1:length(col_id)){
insurance.data[,col_id[i]] <- as.factor(insurance.data[, col_id[i]])
}
col_id
col_class
str(insurance.data.dup)
histogram(insurance.data.dup$age)
histogram(insurance.data.dup$bmi)
histogram(insurance.data.dup$children)
unique(region)
unique(insurance.data.dup$region)
histogram(insurance.data.dup$charges)
histogram(log(insurance.data.dup$charges))
# Classification and Regression Trees
library(rpart)
insurance.data.dup <- read.csv("~/Documents/GitHub/GitHub/Insurance-Claim-Prediction/data/insurance.csv")
insurance.data <- insurance.data.dup
insurance.data$insuranceclaim <- as.factor(ifelse(insurance.data$insuranceclaim == "yes", 1, 0))
set.seed(123457)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
summary(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
set.seed(12345)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
summary(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
# Classification and Regression Trees
library(rpart)
insurance.data.dup <- read.csv("~/Documents/GitHub/GitHub/Insurance-Claim-Prediction/data/insurance.csv")
insurance.data <- insurance.data.dup
insurance.data$insuranceclaim <- as.factor(ifelse(insurance.data$insuranceclaim == "yes", 1, 0))
insurance.data$insuranceclaim
str(insurance.data.dup)
# Classification and Regression Trees
library(rpart)
insurance.data.dup <- read.csv("~/Documents/GitHub/GitHub/Insurance-Claim-Prediction/data/insurance.csv")
insurance.data <- insurance.data.dup
set.seed(12345)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
summary(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
set.seed(12345)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
table(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
fit.allp <- rpart(y ~., method = "class", data = insurance.data.train,
control = rpart.control(minsplit = 1, cp = 0.001))
fit.allp <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(minsplit = 1, cp = 0.001))
fit.allp <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(minsplit = 1, cp = 0.001))
fit.allp
fit.allp <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(minsplit = 1, cp = 0.001))
summary(fit.allp)
printcp(fit.allp)
fit.allp$cptable
max(fit.allp$cptable[,"nsplit"])
max(fit.allp$cptable[,"nsplit"])
min(fit.allp$cptable[,"nsplit"])
plotcp(fit.allp)
(cp= fit.allp$cptable[which.min(fit.allp$cptable[, "xerror"]), "CP"])
(xerr = fit.allp$cptable[which.min(fit.allp$cptable[, "xerror"]), "xerror"])
library(rpart.plot)
rpart.plot(fit.allp, extra = "auto")
plot(fit.allp, uniform = TRUE, main = " ")
text(fit.allp, use.n = TRUE, all = TRUE, cex = .8)
# Plot the 'fit.allp' object with uniform axis scaling
plot(fit.allp, uniform = TRUE, main = "Distribution Plot")
# Add text to the plot using the 'fit.allp' object
text(fit.allp, use.n = TRUE, all = TRUE, cex = 0.8)
# Plot the 'fit.allp' object with larger plot area
par(mar = c(5, 5, 2, 5))  # Adjust the margin to provide more space for labels
plot(fit.allp, uniform = TRUE, main = "Distribution Plot")
# Add text to the plot with adjusted label positions
text(fit.allp, use.n = TRUE, all = TRUE, cex = 0.8, pos = 1)  # Adjust 'pos' parameter if needed
library(ggplot2)
# Assuming fit.allp is a data frame or tibble with x and y columns
ggplot(fit.allp, aes(x = x, y = y, label = label)) +
geom_point() +
geom_text_repel(
box.padding = 0.5,  # Adjust as needed
point.padding = 1,  # Adjust as needed
segment.color = "transparent",  # Hide guiding lines
force = 5,  # Adjust as needed
size = 3  # Adjust text size
) +
labs(title = "Distribution Plot")
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- predict(fit.allp, newdata = bank.data.test, type = "class")
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- predict(fit.allp, newdata = insurance.data.test, type = "class")
(conf_matrix_base <- table(test_df$pred, test_df$actual)) #confusion matrix
library(caret)
sensitivity(conf_matrix_base)
specificity(conf_matrix_base)
(mis.rate <- conf_matrix_base[1, 2] +
conf_matrix_base[2, 1])/sum(conf_matrix_base)
library(caret)
sensitivity(conf_matrix_base)
specificity(conf_matrix_base)
(mis.rate <- conf_matrix_base[1, 2] +
conf_matrix_base[2, 1])/sum(conf_matrix_base)
fit.allf <- rpart(mclass ~., method = "class", data = mr.train,
control = rpart.control(cp = 0.0001))
library(caret)
sensitivity(conf_matrix_base)
specificity(conf_matrix_base)
(mis.rate <- conf_matrix_base[1, 2] +
conf_matrix_base[2, 1])/sum(conf_matrix_base)
fit.allf <- rpart(mclass ~., method = "class", data = insurance.data.train,
control = rpart.control(cp = 0.0001))
library(caret)
sensitivity(conf_matrix_base)
specificity(conf_matrix_base)
(mis.rate <- conf_matrix_base[1, 2] +
conf_matrix_base[2, 1])/sum(conf_matrix_base)
fit.allf <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(cp = 0.0001))
fit.allf <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(cp = 0.0001))
fit.allf <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(cp = 0.0001))
plotcp(fit.allp)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- predict(fit.allp, newdata = insurance.data.test, type = "class")
(conf_matrix_base <- table(test_df$pred, test_df$actual)) #confusion matrix
sensitivity(conf_matrix_base)
specificity(conf_matrix_base)
(mis.rate <- conf_matrix_base[1, 2] +
conf_matrix_base[2, 1])/sum(conf_matrix_base)
#Hyper Parameter Tuning
fit.allf <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(cp = 0.0001))
plotcp(fit.allp)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- predict(fit.allp, newdata = insurance.data.test, type = "class")
(conf_matrix_base <- table(test_df$pred, test_df$actual)) #confusion matrix
sensitivity(conf_matrix_base)
specificity(conf_matrix_base)
(mis.rate <- conf_matrix_base[1, 2] +
conf_matrix_base[2, 1])/sum(conf_matrix_base)
fit.allf <- rpart(insuranceclaim ~., method = "class", data = insurance.data.train,
control = rpart.control(cp = 0.1))
plotcp(fit.allp)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- predict(fit.allp, newdata = insurance.data.test, type = "class")
(conf_matrix_base <- table(test_df$pred, test_df$actual)) #confusion matrix
sensitivity(conf_matrix_base)
specificity(conf_matrix_base)
(mis.rate <- conf_matrix_base[1, 2] +
conf_matrix_base[2, 1])/sum(conf_matrix_base)
#Prune the tree
pfit.allp <- prune(fit.allp, cp =
fit.allp$cptable[which.min(fit.allp$cptable[, "xerror"]), "CP"])
rpart.plot(pfit.allp, extra = "auto")
summary(pfit.allp)
#Measures of Predictive Performance
rootnode_err <- sum(bank.data.train$y==1)/nrow(bank.data.train)
#Measures of Predictive Performance
rootnode_err <- sum(insurance.data.train$insuranceclaim==1)/nrow(bank.data.train)
#Measures of Predictive Performance
rootnode_err <- sum(insurance.data.train$insuranceclaim==1)/nrow(insurance.data.train)
prelerr = pfit.allp$cptable[which.min(pfit.allp$cptable[, "rel error"]), "rel error"]
(presub.err_rate <- rootnode_err*prelerr)
rootnode_err <- sum(insurance.data.train$insuranceclaim==1)/nrow(insurance.data.train)
pxerr = pfit.allp$cptable[which.min(pfit.allp$cptable[, "xerror"]), "xerror"]
(pcv.err_rate <- rootnode_err*pxerr)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- predict(pfit.allp, newdata = insurance.data.test, type = "class")
(conf_matrix_pruned_tree <-
table(test_df$pred, test_df$actual)) #confusion matrix
#library(caret)
sensitivity(conf_matrix_pruned_tree)
specificity(conf_matrix_pruned_tree)
# Missclassification error rate:
(conf_matrix_pruned_tree[1, 2] +
conf_matrix_pruned_tree[2, 1])/sum(conf_matrix_pruned_tree)
# Random Forest
library(ranger)
fit.rf.ranger <- ranger(insuranceclaim ~ ., data = insurance.data.train,
importance = 'impurity', mtry = 3)
# Random Forest
library(ranger)
fit.rf.ranger <- ranger(insuranceclaim ~ ., data = insurance.data.train,
importance = 'impurity', mtry = 3)
print(fit.rf.ranger)
library(vip)
(v1 <- vi(fit.rf.ranger))
library(vip)
(v1 <- vi(fit.rf.ranger))
vip(v1)
pred <- predict(fit.rf.ranger, data = insurance.data.test)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- pred$predictions
(conf_matrix_rf <- table(test_df$pred, test_df$actual)) #confusion matrix
pred
test_df
pred$predictions
pred <- predict(fit.rf.ranger, data = insurance.data.test, , type = "class")
pred <- predict(fit.rf.ranger, data = insurance.data.test,  type = "class")
pred <- predict(fit.rf.ranger, data = insurance.data.test)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA, type = "class")
test_df$pred <- pred$predictions
(conf_matrix_rf <- table(test_df$pred, test_df$actual)) #confusion matrix
pred <- predict(fit.rf.ranger, data = insurance.data.test)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim, pred = NA)
test_df$pred <- pred$predictions
(conf_matrix_rf <- table( test_df$actual, test_df$pred)) #confusion matrix
test_df
pred <- predict(fit.rf.ranger, data = insurance.data.test)
test_df <- data.frame(actual = insurance.data.test$insuranceclaim,  pred = ifelse(pred$predictions > 0.5, 1, 0))
test_df$pred <- pred$predictions
(conf_matrix_rf <- table(test_df$pred, test_df$actual)) #confusion matrix
pred <- predict(fit.rf.ranger, data = insurance.data.test)
test_df$pred <- data.frame(actual = insurance.data.test$insuranceclaim,  pred = ifelse(pred$predictions > 0.5, 1, 0))
(conf_matrix_rf <- table(test_df$pred, test_df$actual)) #confusion matrix
# Assuming your predictions are stored in the variable 'pred'
pred <- predict(fit.rf.ranger, data = insurance.data.test)
# Create a data frame with actual and predicted values
test_df <- data.frame(actual = insurance.data.test$insuranceclaim,
pred = ifelse(pred$predictions > 0.5, 1, 0))
# Create a confusion matrix
conf_matrix_rf <- table(test_df$pred, test_df$actual)
# Display the confusion matrix
print(conf_matrix_rf)
# Sensitivity
sensitivity(conf_matrix_rf)
# Specificity
specificity(conf_matrix_rf)
# Missclassification error rate:
(conf_matrix_rf[1,2] + conf_matrix_rf[2,1])/sum(conf_matrix_rf)
colnames(insurance.data)
fit.rf.ranger <- ranger(insuranceclaim ~ bmi+children+age+smoker+charges+region, data = insurance.data.train,
importance = 'impurity', mtry = 3)
print(fit.rf.ranger)
(v1 <- vi(fit.rf.ranger))
vip(v1)
pred <- predict(fit.rf.ranger, data = insurance.data.test)
# Create a data frame with actual and predicted values
test_df <- data.frame(actual = insurance.data.test$insuranceclaim,
pred = ifelse(pred$predictions > 0.5, 1, 0))
# Create a confusion matrix
conf_matrix_rf <- table(test_df$pred, test_df$actual)
# Display the confusion matrix
print(conf_matrix_rf)
# Sensitivity
sensitivity(conf_matrix_rf)
# Specificity
specificity(conf_matrix_rf)
# Missclassification error rate:
(conf_matrix_rf[1,2] + conf_matrix_rf[2,1])/sum(conf_matrix_rf)
fit.rf.ranger <- ranger(insuranceclaim ~ bmi+children+age+smoker+charges, data = insurance.data.train,
importance = 'impurity', mtry = 3)
print(fit.rf.ranger)
(v1 <- vi(fit.rf.ranger))
vip(v1)
pred <- predict(fit.rf.ranger, data = insurance.data.test)
# Create a data frame with actual and predicted values
test_df <- data.frame(actual = insurance.data.test$insuranceclaim,
pred = ifelse(pred$predictions > 0.5, 1, 0))
# Create a confusion matrix
conf_matrix_rf <- table(test_df$pred, test_df$actual)
# Display the confusion matrix
print(conf_matrix_rf)
# Sensitivity
sensitivity(conf_matrix_rf)
# Specificity
specificity(conf_matrix_rf)
# Missclassification error rate:
(conf_matrix_rf[1,2] + conf_matrix_rf[2,1])/sum(conf_matrix_rf)
# dropped the sex, age and region column
fit.rf.ranger <- ranger(insuranceclaim ~ bmi+children+smoker+charges, data = insurance.data.train,
importance = 'impurity', mtry = 3)
print(fit.rf.ranger)
(v1 <- vi(fit.rf.ranger))
vip(v1)
pred <- predict(fit.rf.ranger, data = insurance.data.test)
# Create a data frame with actual and predicted values
test_df <- data.frame(actual = insurance.data.test$insuranceclaim,
pred = ifelse(pred$predictions > 0.5, 1, 0))
# Create a confusion matrix
conf_matrix_rf <- table(test_df$pred, test_df$actual)
# Display the confusion matrix
print(conf_matrix_rf)
# Sensitivity
sensitivity(conf_matrix_rf)
# Specificity
specificity(conf_matrix_rf)
# Missclassification error rate:
(conf_matrix_rf[1,2] + conf_matrix_rf[2,1])/sum(conf_matrix_rf)
tnc.data <- read.csv("Data/tnc-randeff.csv", header = TRUE)
tnc.data <- read.csv("Data/tnc-randeff.csv", header = TRUE)
dim(tnc.data)
head(tnc.data)
attach(tnc.data)
taxi.zone <- factor(Zoneid)
