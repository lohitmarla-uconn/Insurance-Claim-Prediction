# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
cv_results
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data)
(table <- table(model > 0.5, train_data$insuranceclaim))
accuracy.full <- round((sum(diag(table))/sum(table))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data, )
(table <- table(predictions > 0.5, train_data$insuranceclaim))
accuracy.full <- round((sum(diag(table))/sum(table))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
cv_results
predictions
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table <- as.numeric(predictions > 0.5, train_data$insuranceclaim))
acc <- round((sum(diag(table))/sum(table))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
table
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table <- as.numeric(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table))/sum(table))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table <- (predictions > 0.5, test_data$insuranceclaim))
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
# Binomial Logit Model - K fold validation
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
table.full <- table(predictions > 0.5, test_data$insuranceclaim)
acc <- round((sum(diag(table.full))/sum(table.full))*100, 2)
# Store the accuracy in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
# Binomial Logit Model - K fold validation
# Binomial Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
# Binomial Logit Model - K fold validation
both.logit <- step(full.logit,
direction="both",trace=0, data = insurance.data.train)
# Binomial Both Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
# Binomial Logit Model - K fold validation
# Binomial Both Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- step(full.logit,
direction="both",trace=0, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
#full binary logit model
full.logit <- glm(insuranceclaim ~ . ,data = insurance.data.train,
family = binomial(link = "logit"))
library(ggplot2)
#Reading the csv file
insurance.data.dup <- read.csv("~/Documents/GitHub/GitHub/Insurance-Claim-Prediction/data/insurance.csv")
insurance.data <- insurance.data.dup
str(insurance.data)
nrow(insurance.data)
insurance.data <- unique(insurance.data)
nrow(insurance.data)
print("sex")
table(insurance.data$sex)
print("children")
table(insurance.data$children)
print("smoker")
table(insurance.data$smoker)
print("region")
table(insurance.data$region)
table(insurance.data$insuranceclaim)
sapply(insurance.data, function(x) unique(x))
column_names <- c(
"sex", "children", "smoker", "insuranceclaim", "region"
)
# Convert the selected columns to factors in your data frame
insurance.data[, column_names] <- lapply(insurance.data[, column_names], as.factor)
str(insurance.data)
pairs(insurance.data)
any(is.na(insurance.data))
colSums(is.na(insurance.data)) > 0
percentage_data <- table(insurance.data$insuranceclaim) / nrow(insurance.data) * 100
# Create a data frame for plotting
plot_data <- data.frame(insuranceclaim = as.factor(names(percentage_data)),
percentage = as.numeric(percentage_data))
# Plotting
ggplot(plot_data, aes(x = insuranceclaim, y = percentage)) +
geom_bar(stat = "identity", fill = "skyblue", color = "black") +
geom_text(aes(label = sprintf("%.1f%%", percentage)),
position = position_stack(vjust = 0.5),   # Adjust vjust for vertical position
color = "black", size = 3) +
labs(title = "Distribution of Insurance Claims: Non-Claims (0) vs. Claims (1)",
x = "Insurance Claim",
y = "Percentage")
# Binomial Logit Model - 80-20 split
set.seed(123457)
train.prop <- 0.80
strats <- insurance.data$insuranceclaim
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr,
function(x) sample(x, length(x)*train.prop)))))
insurance.data.train <- insurance.data[idx, ]
insurance.data.test <- insurance.data[-idx, ]
#check for equal proportions of number of claims
table(insurance.data.train$insuranceclaim)/nrow(insurance.data.train)
table(insurance.data.test$insuranceclaim)/nrow(insurance.data.test)
#full binary logit model
full.logit <- glm(insuranceclaim ~ . ,data = insurance.data.train,
family = binomial(link = "logit"))
summary(full.logit)
# Binomial Both Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- step(full.logit,
direction="both",trace=0, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
# Binomial Logit Model - K fold validation
mean(cv_results)
mean(numeric(cv_results))
mean(as.numeric(cv_results))
cv_results
class(cv_results)
str(cv_results)
mean(accuracies)
mean(cv_results)
mean(cv_results, na.rm = TRUE)
cv_results$Accuracies <- as.numeric(cv_results$Accuracies)
# Check the data type again
str(cv_results$Accuracies)
# Now, calculate the mean
mean_accuracy <- mean(cv_results$Accuracies, na.rm = TRUE)
mean_accuracy
# Binomial Both Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- step(full.logit,
direction="both",trace=0, data = train_data)
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
cv_results$Accuracies <- as.numeric(cv_results$Accuracies)
mean_accuracy <- mean(cv_results$Accuracies, na.rm = TRUE)
mean_accuracy
# Binomial Logit Model - K fold validation
# Binomial Full Logit Model - K fold validaton
library(caret)
library(dplyr)
# Set the number of folds (K)
num_folds <- 10
# Create an index vector for splitting
set.seed(123)  # for reproducibility
indices <- createFolds(insurance.data$insuranceclaim, k = num_folds, list = TRUE)
# Initialize a variable to store cross-validation results
cv_results <- data.frame(Accuracies = double(num_folds))
# Perform K-Fold Cross-Validation
for (i in 1:num_folds) {
# Split the data into training and testing sets
train_data <- insurance.data[-indices[[i]], ]
test_data <- insurance.data[indices[[i]], ]
# Fit your model on the training data
model <- glm(insuranceclaim ~ . ,data = train_data,
family = binomial(link = "logit"))
# Make predictions on the test data
predictions <- predict(model, newdata = test_data,  type="response")
(table.full <- table(predictions > 0.5, test_data$insuranceclaim))
acc <- round((sum(diag(table.full))/sum(table.full))*100,2)
# Store the RMSE in the results dataframe
cv_results$Accuracies[i] <- acc
}
# Display cross-validation results
print(cv_results)
cv_results$Accuracies <- as.numeric(cv_results$Accuracies)
mean_accuracy <- mean(cv_results$Accuracies, na.rm = TRUE)
mean_accuracy
# Binomial Logit Model - K fold validation
library(astsa)
data(cmort)
cmort <- ts(cmort)
data(tempr)
tempr <- ts(tempr)
data(part)
part <- ts(part)
#| label: fig-ch10mortality
#| fig.cap: "Time series plots of cmort, tempr, and part."
par(mfrow = c(2, 2))
ts.plot(cmort, main = "", sub = "cmort", xlab = "t")
ts.plot(tempr, sub = "tempr", xlab = "t")
ts.plot(part, sub = "part", xlab = "t")
all <- cbind(cmort, tempr, part)
ts.plot(all, sub = "all three series", lty = 1:3)
#| label: fig-ch10pairs
#| fig.cap: "Matrix scatterplot of cmort, tempr, and part."
pairs(cbind(cmort, tempr, part))
temp <- tempr - mean(tempr)  # center tempr t.s.
temp2 <- temp^2  # form a new var temp^2 squared temp
trend <- time(cmort)
alldat <- cbind(cmort, trend, temp, temp2, part)
n.train <- 496 #length(train set)
n.test <- 12 # length(test set)
train.alldat <- data.frame(alldat[1:n.train,])
test.alldat <- data.frame(alldat[(n.train + 1):nrow(alldat),])
regfit <- lm(cmort ~ trend + temp + temp2 + part, data = train.alldat)
summary(regfit)
summary(aov(regfit))
AIC(regfit)
#| label: fig-ch10mlrresidQQ
#| fig.cap: "Residuals versus fitted values (left) and normal Q-Q plot of
#|  residuals (right) from the MLR model for cmort"
cmort.lmfits <- fitted(regfit)
cmort.lmresid <- resid(regfit)
par(mfrow=c(1,2))
plot(cmort.lmfits, cmort.lmresid, main = "", xlab = "fitted values",
ylab = "residuals")
car::qqPlot(cmort.lmresid, main = "")
#| label: fig-ch10mlrresidplot
#| fig.cap: "Residuals from the MLR model for cmort versus time."
plot(c(1:length(cmort.lmresid)), cmort.lmresid, type = "p",
ylab = "residuals", xlab = "t")
#| label: fig-ch10mlrtsresidplot
#| fig.cap: "Time series plot of residuals of the  MLR model for cmort."
ts.plot(cmort.lmresid, ylab = "residuals", xlab = "t")
#| label: fig-ch10mlrresidacf
#| fig.cap: "ACF plot of residuals of the  MLR model for cmort."
acf(cmort.lmresid, ylim = c(-1, 1), main = "", xlab = "lag h")
library(forecast)
exp(0.24643)
